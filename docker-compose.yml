version: "3.8"
# zookeeper: 172.26.0.10
# kafka: 172.26.0.11
# flink: - job manager 172.26.0.20
#        - task manager(s) random assigment in 172.26.0.0/24
services:
  seata-server:
    image: seataio/seata-server:1.8.0-slim
    container_name: seata-server
    hostname: seata-server
    restart: on-failure
    ports:
      - "7091:7091"
      - "8091:8091"
#    environment:
#      - SEATA_IP=127.0.0.1
#      - SEATA_PORT=7091
#      - STORE_MODE=db
#      - SERVER_NODE=1
#      - SEATA_ENV=dev
#      - SEATA_CONFIG_NAME=/root/registry
  minio:
    container_name: minio
    image: minio/minio
    restart: on-failure
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ~/data/docker/data-middle-platform/data/minio_data/data:/data
      - ~/data/docker/data-middle-platform/data/minio_data/config:/root/.minio
    command: server --console-address ":9001" /data
    environment:
      - MINIO_ACCESS_KEY=admin
      - MINIO_SECRET_KEY=admin123
  mongodb:
    image: mongo
    container_name: mongodb
    hostname: mongodb
    restart: on-failure
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=admin
    ports:
      - "27017:27017"
    volumes:
      - ~/data/docker/data-middle-platform/config/mongo_config/config:/etc/mongo
      - ~/data/docker/data-middle-platform/data/mongo_data/data:/data/db
      - ~/data/docker/data-middle-platform/data/mongo_data/logs:/var/log/mongodb
  mongodb-express:
    image: mongo-express
    container_name: mongo-express
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin
      - ME_CONFIG_MONGODB_ADMINPASSWORD=admin
      - ME_CONFIG_MONGODB_SERVER=mongodb
    restart: on-failure
    ports:
      - "8081:8081"

  elasticsearch:
    image: elasticsearch:8.10.2
    container_name: elasticsearch
    restart: on-failure
    environment:
      - "ES_JAVA_OPTS=-Xms128m -Xmx128m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ~/data/docker/data-middle-platform/data/es_data/data:/usr/share/elasticsearch/data
      - ~/data/docker/data-middle-platform/data/es_data/logs:/usr/share/elasticsearch/logs
#      - ./config/es_config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.26

  nacos:
    image: nacos/nacos-server:v2.2.3
    container_name: nacos
    environment:
      - PREFER_HOST_MODE=ip
      - MODE=standalone
      - SPRING_DATASOURCE_PLATFORM=mysql
      - MYSQL_DATABASE_NUM=1
      - MYSQL_SERVICE_HOST=mysql
      - MYSQL_SERVICE_DB_NAME=nacos
      - MYSQL_SERVICE_PORT=3306
      - MYSQL_SERVICE_USER=root
      - MYSQL_SERVICE_PASSWORD=root
      - MYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useSSL=false&allowPublicKeyRetrieval=true&serverTimezone=UTC
      - JVM_XMS=128m
      - JVM_XMX=128m
      - JVM_XMN=64m
      - JVM_MS=16m
      - JVM_MMS=32m
      - NACOS_AUTH_ENABLE=true
      - NACOS_AUTH_SYSTEM_TYPE=nacos
      - NACOS_AUTH_IDENTITY_KEY=2222
      - NACOS_AUTH_IDENTITY_VALUE=2xxx
      - NACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789
    volumes:
      - ~/data/docker/data-middle-platform/data/nacos_data/logs:/home/nacos/logs
#      - ./data/nacos_data/conf:/home/nacos/conf
    ports:
      - "8848:8848"
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.25
  redis:
    image: redis:7.2.0
    container_name: redis
    hostname: redis
    volumes:
      - ~/data/docker/data-middle-platform/data/redis_data:/data
    ports:
      - "6379:6379"
#    command: redis-server /redis.conf


  mysql:
    image: mysql:8.0.30
    container_name: mysql_8
    hostname: mysql_8
    restart: on-failure
    ports:
      - "3306:3306"
    volumes:
      - ~/data/docker/data-middle-platform/data/mysql_data:/var/lib/mysql
    #      - ./data/mysql_log/mysqld.log:/var/log/mysqld.log
    environment:
      MYSQL_ROOT_PASSWORD: "root" # root密码
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.18
  ZooKeeper:
    image: ubuntu/zookeeper
    container_name: ZooKeeper
    hostname: ZooKeeper
    volumes:
      - ~/data/docker/data-middle-platform/data/zk_data:/data
    ports:
      - "2181:2181"
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.10

  Kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    depends_on:
      - ZooKeeper
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
      KAFKA_MESSAGE_MAX_BYTES: 52428800  # 50M
      KAFKA_CREATE_TOPICS: "topic_one:1:1,topic_two:3:1"
      KAFKA_ZOOKEEPER_CONNECT: ZooKeeper:2181
    volumes:
      - ~/data/docker/data-middle-platform/data/kafka-logs:/kafka
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.11

  FlinkJobManager:
    image: flink:1.17.1-scala_2.12-java8
    container_name: FlinkJobManager
    hostname: FlinkJobManager
    volumes:
      - ~/data/docker/data-middle-platform/data/flink-jobmanager:/data
    expose:
      - "6123"
    links:
      - Kafka
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.20
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: FlinkJobManager

  FlinkTaskManager:
    image: flink:1.17.1-scala_2.12-java8
    #container_name: FlinkTaskManager
    #hostname: FlinkTaskManager
    expose:
      - "6121"
      - "6122"
    depends_on:
      - FlinkJobManager
    command: taskmanager
    deploy:
      replicas: 1
    links:
      - "FlinkJobManager:jobmanager"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: FlinkJobManager
        taskmanager.numberOfTaskSlots: 2
    networks:
      - kafka-flink-cluster-network
  influxdb:
    image: influxdb
    container_name: influxdb
    hostname: influxdb
    ports:
      - "8086:8086"
    volumes:
      - ~/data/docker/data-middle-platform/data/influxdb_data:/var/lib/influxdb
    environment:
      - INFLUXDB_DB=influxdb

  # prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    hostname: 127.0.0.1
    restart: unless-stopped
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
    command: "--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus"
    ports:
      - "9090:9090"
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.21

  # 监控告警WEB UI 配合prometheus使用
  # https://grafana.com/docs/grafana/latest/installation/docker
  grafana:
    image: grafana/grafana:latest
    container_name: prometheus-grafana
    hostname: 127.0.0.1
    restart: unless-stopped
    ports:
      - "3000:3000"
    #    volumes:
    #      - "./grafana/grafana.ini:/etc/grafana/grafana.ini" # 初始化配置（可设置一些告警邮箱等）
    environment:
      GF_EXPLORE_ENABLED: "true"
      # 初始账号密码：admin/admin
      GF_SECURITY_ADMIN_PASSWORD: "admin"
      GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource,alexanderzobnin-zabbix-app"
      # 持久化到mysql数据库
      GF_DATABASE_URL: "mysql://root:root@mysql_8:3306/grafana" # TODO 待修改处（只需创建目标数据库，grafana在启动时会自动初始化相关表）
    depends_on:
      - prometheus
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.22
  loki:
    image: grafana/loki:2.8.2
    container_name: loki
    hostname: loki
    ports:
      - "3100:3100"
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.23
  promtail:
    image: grafana/promtail
    container_name: promtail
    hostname: promtail
    volumes:
      - ~/data/docker/data-middle-platform/logs:/var/log
    networks:
      kafka-flink-cluster-network:
        ipv4_address: 172.26.0.24


    # 网桥
networks:
  kafka-flink-cluster-network:
    # external: true
    driver: bridge
    ipam:
      config:
        - subnet: 172.26.0.0/24

